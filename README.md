# CNN_LSTM_Transformer_CharGen  
**Character-level text generation with CNN + BiLSTM + Transformer!! **

This project is a powerful hybrid character-level language model that combines:
- **CNNs** for local pattern extraction  
- **Bidirectional LSTM** for sequential memory  
- **Transformer Encoder** for global attention  

It predicts the **next character** in a sequence and can generate creative, character-by-character text using a mix of old-school and modern deep learning layers.

---

##  Features

- Character-level text generation  
- CNN â†’ BiLSTM â†’ Transformer pipeline  
- Hyperparameter tuning with **Optuna**  
- Accuracy + loss evaluation  
- Sample text generation  

---

## How to Use

1. **Install requirements**  
```bash
pip install -r requirements.txt

It will:
Train using Optuna hyperparameter tuning
Save the best model
Evaluate character prediction accuracy
Generate sample text



Author
Made with love by Mehrta ðŸ’«
MSc Artificial Intelligence - University of Birmingham

